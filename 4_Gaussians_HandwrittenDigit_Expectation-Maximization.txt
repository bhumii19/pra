import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_digits
from sklearn.decomposition import PCA
from sklearn.mixture import GaussianMixture
from sklearn.metrics import accuracy_score, confusion_matrix
from scipy.stats import mode

# 1. Load the handwritten digits dataset
digits = load_digits()
X, y = digits.data, digits.target
print(f"Dataset shape: {X.shape}")  # (1797, 64)

# 2. EDA
print("\nBasic Info:")
print(f"Number of samples: {X.shape[0]}")
print(f"Number of features (pixels): {X.shape[1]}")
print("Target classes:", np.unique(y))

# Plot class distribution
sns.countplot(x=y)
plt.title("Digit Class Distribution")
plt.xlabel("Digit")
plt.ylabel("Count")
plt.show()

# Visualize some digits
fig, axes = plt.subplots(2, 5, figsize=(10, 5))
for i, ax in enumerate(axes.flat):
    ax.imshow(digits.images[i], cmap='gray')
    ax.set_title(f"Label: {digits.target[i]}")
    ax.axis('off')
plt.suptitle("Sample Digit Images")
plt.tight_layout()
plt.show()

# 3. PCA for Dimensionality Reduction
pca = PCA(n_components=30, whiten=True, random_state=42)
X_pca = pca.fit_transform(X)
print(f"Explained variance by PCA (30 components): {np.sum(pca.explained_variance_ratio_):.2f}")

# 4. Fit GMM using EM
gmm = GaussianMixture(n_components=10, covariance_type='full', random_state=42)
gmm.fit(X_pca)
y_pred = gmm.predict(X_pca)

# 5. Map GMM clusters to true labels using majority vote
def map_clusters_to_labels(y_pred, y_true):
    labels = np.zeros_like(y_pred)
    for i in range(10):
        mask = (y_pred == i)
        if np.any(mask):
            labels[mask] = mode(y_true[mask])[0]
    return labels

y_mapped = map_clusters_to_labels(y_pred, y)

# 6. Evaluation
accuracy = accuracy_score(y, y_mapped)
conf_matrix = confusion_matrix(y, y_mapped)
print(f"\nGMM Clustering Accuracy: {accuracy:.2f}")
print("Confusion Matrix:\n", conf_matrix)

# 7. Visualization
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='tab10', s=10)
plt.title("True Labels (PCA Projection)")

plt.subplot(1, 2, 2)
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_mapped, cmap='tab10', s=10)
plt.title("GMM Clustered Labels")

plt.tight_layout()
plt.show()
